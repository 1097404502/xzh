[toc]

# 超售问题

max_over_subscription_ratio
# 错误的命令
## cinder ceph-pool-list
[root@node01 ~]# cinder ceph-pool-list
ERROR: Internal Server Error: 'id' (HTTP 500) (Request-ID: req-d44da9d4-aa71-46d6-9933-9b53434d07b9)

## cinder ceph-status
[root@node01 ~]# cinder ceph-status
ERROR: Internal Server Error: 'overall_status' (HTTP 500) (Request-ID: req-5d00c822-0c88-4c22-b3a8-a1d905cd6e76)

# 安装 docker ce
```bash

cat > /etc/apt/sources.list.d/docker.list << "EOF"
deb [arch=amd64] https://download.docker.com/linux/ubuntu bionic stable
EOF

$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -


sudo apt update ; sudo  apt install docker-ce -y

docker --version

sudo service docker start

sudo service docker status

sudo systemctl start docker.service

sudo systemctl enable docker

sudo systemctl status docker

```


# docker-compose

```bash
cd /home/lmk/codes/cinder/contrib/block-box
docker-compose up

```

# 问题定位

```bash

cd /home/lmk/codes/cinder_old/cinder
#  grep  "被查找的字符串" –r 文件目录
grep  "update a ceph" -r /home/lmk/codes/cinder_old

```


```bash

/home/lmk/codes/cinder_old/cinder/api/contrib/osd_manage.py

def detail(self, req):
    context = req.environ['cinder.context']
    try:
        res = self.ceph_api.get_all_osds(context)

```

# 定位代码中的日志输出
```bash

grep "LOG."  -r /home/lmk/codes/cinder_old/cinder/api/contrib

```

# 服务器上代码的位置
```bash

/usr/lib/python2.7/site-packages/cinder

```

# 定位在cinderclient 中的位置
```bash
grep "ceph-pool" -r /home/lmk/codes/cinderclient
# 最相似的 匹配
/home/lmk/codes/cinderclient/v2/ceph_pools.py:            return self._list("/os-ceph-pool/detail", "ceph_pool")
/home/lmk/codes/cinderclient/v2/ceph_pools.py:            return self._list("/os-ceph-pool", "ceph_pool")

```


```bash

grep "ceph_pool_list" -r /home/lmk/codes/cinderclient
/home/lmk/codes/cinderclient/v2/shell.py:def do_ceph_pool_list(cs, args):

```

# 修改函数查看报错原因
```bash

/home/lmk/codes/cinderclient/v2/shell.py:def do_ceph_pool_list(cs, args):

cs:
<cinderclient.v2.client.Client object at 0x7f65acd1ad50>


args:
Namespace(bypass_url='', debug=False, detail=None, endpoint_type=None, func=<function do_ceph_pool_list at 0x7f0f2d3ab668>, help=False, insecure=False, os_auth_strategy='keystone', os_auth_system='', os_auth_url='http://192.168.41.10:35357/v3', os_cacert=None, os_cert=None, os_endpoint_type='publicURL', os_key=None, os_password='internal@zettakit.com', os_project_domain_id='', os_project_domain_name='default', os_project_id='', os_project_name='ADMIN@INTERNAL', os_region_name='', os_tenant_id='', os_tenant_name='ADMIN@INTERNAL', os_token='', os_url='', os_user_domain_id='', os_user_domain_name='default', os_user_id='', os_username='ADMIN@INTERNAL', os_volume_api_version='2', profile=None, retries=0, service_name='', service_type=None, timeout=600, volume_service_name='')




```

## 调用层次
```bash

/home/lmk/codes/cinderclient/v2/shell.py:def do_ceph_pool_list(cs, args):

pool_list = cs.ceph_pools.list(detail=detail)

ceph_pools:
self.ceph_pools = ceph_pools.CephPoolsManager(self)

list():
return self._list("/os-ceph-pool", "ceph_pool")

```

## _list 实际的请求函数
```bash

def _list(self, url, response_key, obj_class=None, body=None,
              limit=None, items=None, with_count=False):
        resp = None
        if items is None:
            items = []
        if body:
            resp, body = self.api.client.post(url, body=body)
        else:
            resp, body = self.api.client.get(url)

        if obj_class is None:
            obj_class = self.resource_class

        data = body[response_key]
        # NOTE(ja): keystone returns values as list as {'values': [ ... ]}
        #           unlike other services which just return the list...
        if isinstance(data, dict):
            try:
                data = data['values']
            except KeyError:
                pass

        with self.completion_cache('human_id', obj_class, mode="w"):
            with self.completion_cache('uuid', obj_class, mode="w"):
                items_new = [obj_class(self, res, loaded=True)
                             for res in data if res]
        if limit:
            limit = int(limit)
            margin = limit - len(items)
            if margin <= len(items_new):
                # If the limit is reached, return the items.
                items = items + items_new[:margin]
                if with_count:
                    return (common_base.ListWithMeta(items, resp),
                            body.get('count', None))
                return common_base.ListWithMeta(items, resp)
            else:
                items = items + items_new
        else:
            items = items + items_new

        # It is possible that the length of the list we request is longer
        # than osapi_max_limit, so we have to retrieve multiple times to
        # get the complete list.
        next = None
        if 'volumes_links' in body:
            volumes_links = body['volumes_links']
            if volumes_links:
                for volumes_link in volumes_links:
                    if 'rel' in volumes_link and 'next' == volumes_link['rel']:
                        next = volumes_link['href']
                        break
            if next:
                # As long as the 'next' link is not empty, keep requesting it
                # till there is no more items.
                items = self._list(next, response_key, obj_class, None,
                                   limit, items)
        if with_count:
            return common_base.ListWithMeta(items, resp), body.get('count', None)
        return common_base.ListWithMeta(items, resp)

```

## 最后定位到 client 错误位置,请求报错
```bash

this is _list call
url : /os-ceph-pool
key : ceph_pool
api : <cinderclient.v2.client.Client object at 0x7f1366ef0350>
ERROR: Internal Server Error: 'id' (HTTP 500) (Request-ID: req-445f75b7-049c-4e4d-82d0-5a561982f9ec)


```

## 继续去 server 端 寻找错误
```bash

[root@node01 ~]# grep "os-ceph-pool" -r /usr/lib/python2.7/site-packages/cinder
/usr/lib/python2.7/site-packages/cinder/api/contrib/pool_manage.py:    alias = "os-ceph-pool"
/usr/lib/python2.7/site-packages/cinder/api/contrib/pool_manage.py:    namespace = "http://docs.openstack.org/volume/ext/os-ceph-pool/api/v2"


```

```bash
grep "Internal Server" -r /usr/lib/python2.7/site-packages/cinder
/usr/lib/python2.7/site-packages/cinder/api/contrib/pool_manage.py:            msg = (_('Internal Server Error: %(err)s') % {'err': err.msg})
/usr/lib/python2.7/site-packages/cinder/api/contrib/pool_manage.py:            msg = (_('Internal Server Error: %(err)s') %
/usr/lib/python2.7/site-packages/cinder/api/contrib/pool_manage.py:            msg = (_('Internal Server Error: %(err)s') % 
....
/usr/lib/python2.7/site-packages/cinder/exception.py:    message = _("Internal Server Error: %(err)s")


[root@node01 ~]# cinder ceph-pool-list
raise 
args  ('/os-ceph-pool', 'GET')
kwargs  {'authenticated': True}
resp  <Response [500]>
body  {u'computeFault': {u'message': u"Internal Server Error: 'id'", u'code': 500}}

```

# 实际请求代码
```bash


class SessionClient(adapter.LegacyJsonAdapter):

    def request(self, *args, **kwargs):
        kwargs.setdefault('authenticated', False)
        # Note(tpatil): The standard call raises errors from
        # keystoneclient, here we need to raise the cinderclient errors.
        raise_exc = kwargs.pop('raise_exc', True)
        resp, body = super(SessionClient, self).request(*args,
                                                        raise_exc=False,
                                                        **kwargs)

adapter
/usr/lib/python2.7/site-packages/keystoneclient
192.168.41.1:/os-ceph-pool


```

# 修改代码后重启 cinder api 服务
```bash

scp -r /usr/lib/python2.7/site-packages/cinder root@192.168.41.2:/usr/lib/python2.7/site-packages
scp -r /usr/lib/python2.7/site-packages/cinder root@192.168.41.3:/usr/lib/python2.7/site-packages

systemctl stop openstack-cinder-api
systemctl start openstack-cinder-api
systemctl status openstack-cinder-api


# service 内容
openstack-cinder-api
/usr/bin/cinder-api --config-file /usr/share/cinder/cinder-dist.conf --config-file /etc/cinder/cinder.conf --logfile /var/log/cinder/api.log

# 服务器实例信息
('server  attrs :', ['__abstractmethods__', '__class__', '__delattr__', '__dict__', '__doc__', '__format__', '__getattribute__', '__hash__', '__init__', '__module__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_cache', '_abc_negative_cache', '_abc_negative_cache_version', '_abc_registry', '_get_manager', 'app', 'host', 'loader', 'manager', 'name', 'port', 'reset', 'server', 'start', 'stop', 'wait', 'workers'])
('server ', <cinder.service.WSGIService object at 0x7f0f4cffb850>)
('workers ', 12)
('host ', '192.168.41.1')
('manager ', None)
('port ', 8776)
('name', 'osapi_volume')


http://192.168.41.1:8776/os-ceph-pool

# 搜索任务
ps -aux|grep "/usr/bin/cinder-api"
cinder_api_pid=`ps -aux|grep "/usr/bin/cinder-api"|grep -v grep|awk '{print $2}'`

```

# web段 请求的内容
```bash

http://192.168.41.1/api/backend_storages/pools

Referer: http://192.168.41.1/index/infrastructure/storage_backend/storage_pool

{"status": 400, "msg": "\u5185\u90e8\u670d\u52a1\u5668\u9519\u8bef: ['id'] . "}

所以继续查询linux 端口占用
[root@node01 ~]# lsof -i:80
COMMAND   PID    USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME
nginx    6827    root    9u  IPv4   81173      0t0  TCP node01:http (LISTEN)
nginx    6849   nginx    9u  IPv4   81173      0t0  TCP node01:http (LISTEN)

继续查询 nginx



ps -aux|grep "/usr/bin/cinder-api"

ps -aux|grep "nginx"
root  6827  0.0  0.0  46608  1992 ? Ss 9:48   0:00 nginx: master process /usr/sbin/nginx -c /etc/nginx/nginx.conf

[root@node01 ~]# ls /etc/nginx/conf.d/
/etc/zettakit/zettakit.conf

zettakit.conf  zkeeper.conf

# 查找后发现

zettakit.conf 中有我们所需要的 api 转发 

upstream flask_servers {
    ip_hash;
    server 192.168.41.1:8881;
    server 192.168.41.1:8882;
    server 192.168.41.1:8883;
    server 192.168.41.1:8884;
}

location /api {
    proxy_pass http://flask_servers/;
    proxy_set_header Host $host;
    proxy_connect_timeout   30;
    proxy_read_timeout      180;
    proxy_next_upstream     error timeout;
    proxy_request_buffering off;
}

lsof -i:8881


gunicorn 16684 celery   17u  IPv4  88823      0t0  TCP *:galaxy4d (LISTEN)

ps -aux|grep "gunicorn"

backend_storages/pools

grep "backend_storages" -r /usr/lib/python2.7/

 grep "backend_storages" -r /usr/lib/python2.7/
/usr/lib/python2.7/site-packages/cinder/api/views/backend_storage.py:    def summary_list(self, backend_storages):
/usr/lib/python2.7/site-packages/cinder/api/views/backend_storage.py:        return self._list_view(self.summary, backend_storages)
/usr/lib/python2.7/site-packages/cinder/api/views/backend_storage.py:    def _list_view(self, func, backend_storages):
/usr/lib/python2.7/site-packages/cinder/api/views/backend_storage.py:            backend_storage in backend_storages]
/usr/lib/python2.7/site-packages/cinder/db/sqlalchemy/models.py:    __tablename__ = 'backend_storages'

cd /usr/share/vertex
celery     15944  0.0  0.0 334720 62976 ?        Ss   09:48   0:01 /usr/bin/python2 /usr/bin/gunicorn --worker-class geventwebsocket.gunicorn.workers.GeventWebSocketWorker start:app --bind 127.0.0.1:8001 --preload --log-file /var/log/celery/gunicorn.log

pkill -9 "/usr/bin/gunicorn"
 
kill -9 $(ps -ef|grep gunicorn|gawk '$0 !~/grep/ {print $2}' |tr -s '\n' ' ')
ps -aux|grep "gunicorn"

cd /usr/share/vertex ; /usr/bin/python2 /usr/bin/gunicorn --worker-class geventwebsocket.gunicorn.workers.GeventWebSocketWorker start:app --bind 127.0.0.1:8001 --preload --log-file /var/log/celery/gunicorn.log;

 systemctl start gunicorn
 systemctl status gunicorn


```

# 重启前端服务
```bash

systemctl restart php-fpm
systemctl restart nginx
systemctl restart gunicorn
systemctl restart celery
systemctl restart celerybeat
systemctl restart openstack-cinder-api


journalctl -u gunicorn

journalctl -u openstack-cinder-api

gunicorn[1826771]: Error: Error: '/var/log/celery/gunicorn.log' isn't writable [IOError(13, 'Permission denied')]


grep "Internal Server Error:" -r /var/log/cinder

# 分发文件
scp -r /usr/lib/python2.7/site-packages/cinder/api root@192.168.41.2:/usr/lib/python2.7/site-packages/cinder/api
scp -r /usr/lib/python2.7/site-packages/cinder/api root@192.168.41.3:/usr/lib/python2.7/site-packages/cinder/api


grep "Internal Server Error:" -r /var/log/cinder

grep "func_name :" -r /var/log/cinder

grep "exception err : " -r  /var/log/cinder

grep "outbuf :" -r  /var/log/cinder


grep "get_all_pools outbuf " -r  /var/log/cinder


```



# 拿到的 出错的 信息
## 原有错误 Internal Server Error:'overall_status'
## 新错误 Unable to get backend storage status.. reason: AttributeError("'NoneType' object has no attribute 'iteritems'",)
get_all_status  outbuf 
具体内容 参见 
get_all_status中的outbuf

拷贝到 浏览器 的 console a = ...

即可查看格式化 的 json对象


如下命令不会覆盖目标地址的同名文件夹

scp -r /home/hadoop/hadoop-2.7.7/ root@node1:/home/hadoop/hadoop-2.7.7
使用以下命令可覆盖。

scp -r /home/hadoop/hadoop-2.7.7/    root@node1:/home/hadoop/

scp -r /usr/lib/python2.7/site-packages/ root@192.168.41.2:/usr/lib/python2.7/


# 两个问题分别对应的 文件

## 问题1
Internal Server Error:'overall_status' 
-->  /usr/lib/python2.7/site-packages/cinder/volume/ceph_api.py
修改之后
Unable to get backend storage status.. reason: AttributeError("'NoneType' object has no attribute 'iteritems'",)


## 问题2
Internal Server Error:'id'
-->  /usr/lib/python2.7/site-packages/cinder/api/contrib/pool_manage.py 



